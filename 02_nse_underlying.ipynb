{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Underlying details extracted from nse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import json\n",
    "import datetime as datetime\n",
    "\n",
    "#******        Flags and Variables        ***\n",
    "#_______________________________________________\n",
    "\n",
    "load_from_pickle = True   # For underlying symbol list\n",
    "\n",
    "\n",
    "#******   Error catch in list comprehension  ****\n",
    "#________________________________________________\n",
    "\n",
    "def catch(func, handle=lambda e : e, *args, **kwargs):\n",
    "    '''List comprehension error catcher'''\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "# get / make the symbols list\n",
    "if load_from_pickle:\n",
    "    symbols = pd.read_pickle('./zdata/nse_equity_options.pkl').Symbol.unique()\n",
    "else:\n",
    "    symbols = list(pd.read_csv('./zdata/nse_equity_symbols.csv'))\n",
    "\n",
    "def get_underlying(symbol):\n",
    "    \n",
    "    '''Gets the underlying data\n",
    "    Arg: (symbol as string)\n",
    "    Returns: df as dataframe'''\n",
    "\n",
    "    # URLs\n",
    "    url_base1 = \"https://www.nseindia.com/live_market/dynaContent/live_watch/\"\n",
    "    url = url_base1 + \"get_quote/GetQuote.jsp?symbol=\"+symbol\n",
    "\n",
    "    page = requests.get(url).text\n",
    "\n",
    "    # soup out the json dict\n",
    "    bs_nse = bs4(page, 'html.parser')\n",
    "    json_nse = json.loads(bs_nse.find(id='responseDiv').text.strip())\n",
    "\n",
    "    df = pd.DataFrame.from_dict(json_nse['data'][0], orient='index').T\n",
    "    \n",
    "    return df\n",
    "\n",
    "nse_underlyings = [catch(lambda: get_underlying(symbol)) for symbol in symbols]\n",
    "\n",
    "df_nse_und = pd.concat(nse_underlyings).set_index('symbol')\n",
    "\n",
    "# clean up the commas, dashes and empty strs\n",
    "df_nse_und1 = df_nse_und.replace(',|-' , '', regex=True)\n",
    "df_nse_und1 = df_nse_und1.replace('', np.nan)\n",
    "\n",
    "# convert date columns to datetime.date format\n",
    "filtin = ['Date', 'dt']\n",
    "filtout = ['isExDateFlag']\n",
    "date_columns_mask = df_nse_und1.columns.str.contains('|'.join(filtin)) | (df_nse_und1.columns.str.contains('|'.join(filtout)))\n",
    "dt_col_list = df_nse_und1.loc[:, date_columns_mask].columns.tolist()\n",
    "dt_col_list = [item for item in dt_col_list if item not in filtout]\n",
    "\n",
    "df_nse_und1.loc[:, dt_col_list] = df_nse_und1.loc [:, dt_col_list].apply( \\\n",
    "                                  pd.to_datetime, errors= 'coerce').applymap(pd.Timestamp.date)\n",
    "\n",
    "dict_df = df_nse_und1.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df_nse_und1.to_pickle('./zdata/underlying_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignored because dataframe pickle occupies lesser space!\n",
    "# import pickle\n",
    "# with open('./zdata/underlying_dict.pkl', 'wb') as handle:\n",
    "#     pickle.dump(dict_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
