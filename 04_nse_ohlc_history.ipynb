{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to pickle historical data for SD of nse underlyings\n",
    "\n",
    "# STATUS: Completed\n",
    "\n",
    "#***          Start ib_insync (run once)       *****\n",
    "#___________________________________________________\n",
    "\n",
    "from ib_insync import *\n",
    "util.startLoop()\n",
    "# ib=IB().connect('127.0.0.1', 7496, clientId=3) # kavi TWS live\n",
    "ib=IB().connect('127.0.0.1', 4001, clientId=3) # kavi IBG live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ib_insync.client:Started to throttle requests\n",
      "WARNING:ib_insync.client:Stopped to throttle requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ib_insync.wrapper:Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "ERROR:ib_insync.wrapper:Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "ERROR:ib_insync.wrapper:Error 1102, reqId -1: Connectivity between IB and Trader Workstation has been restored - data maintained.\n",
      "ERROR:ib_insync.wrapper:Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "ERROR:ib_insync.wrapper:Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "ERROR:ib_insync.wrapper:Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "ERROR:ib_insync.client:An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "#******         Paths and variables         ****\n",
    "#_______________________________________________\n",
    "\n",
    "datapath = r'./zdata/'\n",
    "market = 'NSE'\n",
    "default_duration = 365 # days\n",
    "\n",
    "#******   Error catch in list comprehension  ****\n",
    "#________________________________________________\n",
    "\n",
    "def catch(func, handle=lambda e : e, *args, **kwargs):\n",
    "    '''List comprehension error catcher'''\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "#***      Function to get historical data     *****\n",
    "#___________________________________________________\n",
    "def get_hist(contract, duration):\n",
    "    '''Gets 1-day bars of contracts for the duration specified\n",
    "    Args:\n",
    "        (contract) as obj\n",
    "        (duration) as int\n",
    "    Returns: dataframe of symbol, date, ohlc, avg and volume \n",
    "    '''\n",
    "    \n",
    "    # Prepare the duration\n",
    "    strduration = str(duration) + ' D'\n",
    "    \n",
    "    # Extract the history\n",
    "    hist = ib.reqHistoricalData(contract=contract, endDateTime='', \n",
    "                                    durationStr=strduration, barSizeSetting='1 day',  \n",
    "                                                whatToShow='Trades', useRTH=True)\n",
    "\n",
    "    # Make the dataframe\n",
    "    cols=['ibSymbol', 'D', 'O', 'H', 'L', 'C', 'Avg', 'Vol']\n",
    "    df = pd.DataFrame([(contract.symbol, h.date, h.open, h.high, h.low, \n",
    "                       h.close, h.average, h.volume) \n",
    "                      for h in hist], columns=cols)\n",
    "    return df\n",
    "\n",
    "#*****    Get the symbols lists    ****\n",
    "#_____________________________________*\n",
    "symbols = list(pd.read_pickle(datapath+'df_underlying.pkl')['ibSymbol'])\n",
    "\n",
    "indexes = list(pd.read_pickle(datapath+'df_nse_idx_symbols.pkl')['ibSymbol'])\n",
    "equities = list(pd.read_pickle(datapath+'df_nse_eq_symbols.pkl')['ibSymbol'])\n",
    "\n",
    "#*****    Qualify the contracts    ****\n",
    "#_____________________________________*\n",
    "\n",
    "# make the contracts and qualify them for symbols in underlying.pkl\n",
    "contracts = [Index(symbol=s, exchange=market) \n",
    " if s in indexes \n",
    " else Stock(symbol=s, exchange=market) \n",
    " for s in symbols]\n",
    "\n",
    "qual_contracts = ib.qualifyContracts(*contracts)\n",
    "\n",
    "#***            FIRST-RUN OHLC              ***\n",
    "#______________________________________________\n",
    "\n",
    "# Check if pickle file exists\n",
    "f_exists = os.path.isfile(datapath+r'df_ohlc.pkl')\n",
    "\n",
    "# Generate the entire pickle if it doesn't exist\n",
    "# Takes about 8 mins for 365 days for 207 scrips\n",
    "\n",
    "if not f_exists:\n",
    "    df = [get_hist(contract=c, duration=365) for c in contracts]\n",
    "\n",
    "    # concatenate the list of dataframes and pickle\n",
    "    df1 = pd.concat(df).reset_index(drop=True)\n",
    "    df1.to_pickle(datapath+r'df_ohlc.pkl')\n",
    "\n",
    "#*****    Append OHLC for missing dates   ****\n",
    "#_____________________________________________\n",
    "\n",
    "# Get pickled data from disk\n",
    "df_raw = pd.read_pickle(datapath+r'df_ohlc.pkl')\n",
    "\n",
    "if f_exists:\n",
    "    \n",
    "    '''Missing OHLC dates / symbols to be added to the pickle'''\n",
    "    \n",
    "    #...........   Missing dates   .......\n",
    "    #.....................................\n",
    "\n",
    "    # Get the last date of the pickle \n",
    "    last_dt = df_raw.loc[(df_raw.ibSymbol == df_raw.ibSymbol[0]), 'D'].max()\n",
    "\n",
    "    # Get the latest date of ib.reqHistoricalData\n",
    "    c = Stock(symbol=df_raw.ibSymbol[0], exchange=market) # first symbol's contract\n",
    "\n",
    "    latest_dt = ib.reqHistoricalData(contract=c,\n",
    "                                     endDateTime= '', durationStr='1 D', barSizeSetting='1 day', \n",
    "                                     whatToShow='Trades', useRTH=True)[0].date\n",
    "\n",
    "    delta_days = (latest_dt - last_dt).days    # additonal days required\n",
    "\n",
    "    #.....      Correct the duration string    ....\n",
    "    #..............................................\n",
    "    if delta_days > 0:\n",
    "        duration = str(delta_days)+ ' D'\n",
    "        dates_list = [d.date for d in ib.reqHistoricalData(contract=c, endDateTime='',\n",
    "                                   durationStr=duration, barSizeSetting='1 day', \n",
    "                                   whatToShow='Trades', useRTH=True)]\n",
    "\n",
    "        # Correct delta days duration to points of data available.\n",
    "        # This would be the duration string for ib.reqHistoricalData delta\n",
    "        duration1 = len([d for d in dates_list if d >= last_dt])\n",
    "\n",
    "        delta = [get_hist(contract=c, duration=duration1) for c in contracts]\n",
    "\n",
    "        df_delta = pd.concat(delta).reset_index(drop=True)\n",
    "\n",
    "        # Append to create the new data frame\n",
    "        df_raw = pd.concat(objs=[df_raw, df_delta], \n",
    "                           axis=0).sort_values(['ibSymbol', 'D']).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "    #......... Missing Symbols handling ......\n",
    "    #.........................................\n",
    "    \n",
    "    # Get the missing symbols in the pickle\n",
    "    missing_syms = list(set([c.symbol for c in contracts]) - set(df_raw.ibSymbol.unique()))\n",
    "    \n",
    "\n",
    "    # If symbols are missing\n",
    "    if not missing_syms:\n",
    "        missing_contracts = [c for c in contracts if c.symbol in missing_syms]\n",
    "        missing = [get_hist(contract=c, duration=default_duration) for c in missing_contracts]\n",
    "        df_missing = pd.concat(missing).reset_index(drop=True)\n",
    "\n",
    "        # Add it to df_raw\n",
    "        df_raw = pd.concat(objs=[df_raw, df_missing], \n",
    "                            axis=0).sort_values(['ibSymbol', 'D']).reset_index(drop=True)\n",
    "\n",
    "    # Overwrite the pickled file\n",
    "    df_raw.to_pickle(datapath+r'df_ohlc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
